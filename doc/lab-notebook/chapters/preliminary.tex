\chapter{Preliminary}
\label{ch:preliminary}

Initially we want to match one of the papers and use ResNet-32 with the CIFAR-10
dataset.

It appears transient servers and spot instances are more expensive now.
In 2016 they were 70\% cheaper with Google, and 90\% cheaper with Amazon than
dedicated servers.

Add in \href{https://github.com/google-research/bert}{BERT} models.

\section{Synthetic Scalability Tests}
For these tests, I ran the standard Horovod synthetic benchmakr tests for
the ResNet50 model.
This benchmark runs on a synthetic image dataset to measure the throughput in
images per second given a particular configuration.
I ran two separate versions of the scalability experiments, a \texttt{Clustered}
version in which multiple GPUs are collocated on a single instance (such as a
p3.8xlarge) and a \texttt{Spread} version in which each instance had a single GPU and
were spread across multiple Availability Zones.
Each test used the p3 instance type which are equipped with V100 GPUs.

\begin{center}
\includestandalone[scale=1.25]{../figures/resnet50-synthetic-scalability}
\end{center}

\subsection{Experimental Results}
\begin{itemize}
    \item The obvious (and expected) takeaway is that the clustered throughput
        scaled significantly better.
    \begin{itemize}
        \item \texttt{Clustered} Avg Scaling Factor: 90\%
        \item \texttt{Spread} Avg Scaling Factor: 50\%
    \end{itemize}
    \item Need to consider tradeoff of higher availability vs lower throughput
    \begin{itemize}
        \item If we have a single machine with many GPUs, we get better perf
            but getting preempted means losing all work
    \end{itemize}
\end{itemize}


\section{Horovod Elastic Tests}
Shen found that there already exists a Horovod benchmark with dynamic
cluster management.
Our goal is to run this framework in elastic mode and compare its performance
with the on-demand version where no servers will join or leave during
computation.

\vspace{1em}
\textbf{Initial Question to Answer:} Is there still room for improvement for
\emph{Dynamic Clusters using Data Parallelism (DP)}.
\begin{itemize}
    \item Does the Elastic version incur excessively high overhead when
      adding or losing server?
    \item Does the accuracy take a hit from the dynamic aspect of the system?
    \item Specifically, are there research challenges involved in solving these
      issues?
\end{itemize}

\vspace{1em}
Focus on validating DP for these experiments because if we cannot find significant
contributions at the level of DP then we should shift our focus to Model
Parallelism (MP).

\vspace{2em}
TO GO HERE:
\begin{itemize}
    \item Performance and accuracy numbers of Horovod elastic vs Horovod stable
    \item Ideally run over several attempts to mitigate variability caused by
      using NFS server to store data
\end{itemize}

\vspace{2em}
\textbf{Follow-up Discussion from 01/13/21 - In Depth Meeting} \\
High level discussion topics related to dataset partitioning and Data Paralellism:
\begin{itemize}
    \item Data partitioning: Harry's region based partitiong proposal
    \begin{itemize}
        \item Given $r$ regions (partitions essentially) and $N$ nodes, each
          region gets $N/r$ workers.
        \item If region $r_i$ loses some workers and region $r_j$ still has all
          workers $\rightarrow$ transfer some workers from $r_j$ to $r_i$
        \item In each region $\rightarrow$ use the PyTorch Distributed Data Sampler
          to make sure each minibatch is not-overlapping
    \end{itemize}

    \item Data partitioning: Small chunk-based partitioning
    \begin{itemize}
        \item Divide the whole dataset up into small chunks (100MB for example)
        \item Store on S3
        \item When worker fails, distribute its chunks to all remaining workers
        \item When workers added redistribute extra chunks to maintain roughly equal
          workload
        \item \textbf{Question:} If we keep losing workers, how will we eventually run
          when there is more data than the workers can fit on their disks? (I guess
          this goes for any method of partitioning though...)
    \end{itemize}
\end{itemize}

\vspace{1em}
High level discussion related to exploring model parallelism (MP)
\begin{itemize}
    \item \textbf{Main Question:} How to ensure reliability when running MP on
      transient servers?
    \item \textbf{Suggested Solutions (Very high level):}
    \begin{itemize}
        \item Split model into smaller parts than necessary $\rightarrow$
          if minimum GPUs required for model to fit, split model into 6 parts
        \item Run small copies redundantly on other GPUs $\rightarrow$ if we
          lose a worker with some portions of the model other GPUs will have that
          portion
        \item Use some form of \textbf{erasure coding} to reconstruct missing data?
        \begin{itemize}
            \item What would erasure coding look like in this context?
        \end{itemize}
    \end{itemize}
\end{itemize}

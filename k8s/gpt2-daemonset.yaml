
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: gpt2
  namespace: elastic-job
spec:
  selector:
    matchLabels:
      app: gpt2
  template:
    metadata:
      namespace: elastic-job
      labels:
        app: gpt2
    spec:
      nodeSelector:
        eks.amazonaws.com/nodegroup: ng-1
      containers:
      - name: elasticjob-worker
        image: 416609528037.dkr.ecr.us-west-2.amazonaws.com/project-pactum:0.1.0-210
        imagePullPolicy: Always
        command: ["python", "-m", "project_pactum.run"]
        args:
          - "--rdzv_backend=etcd"
          - "--rdzv_endpoint=etcd-service:2379"
          - "--rdzv_id=gpt2"
          - "--nnodes=1:64"
          - "--nproc_per_node=1"
          - "--project-pactum"
          - "--max-pipe-parallel-size=24"
          - "/workspace/external/deepspeed/DeepSpeedExamples/Megatron-LM-v1.1.5-3D_parallelism/pretrain_gpt2.py"
          - "--model-parallel-size=1"
          - "--num-layers=24"
          - "--hidden-size=1024"
          - "--num-attention-heads=16"
          - "--seq-length=1024"
          - "--max-position-embeddings=1024"
          - "--batch-size=4"
          - "--gas=16"
          - "--train-iters=320000"
          - "--lr-decay-iters=320000"
          - "--save=/data/checkpoint"
          - "--load=/data/checkpoint"
          - "--data-path=/data/my-gpt2_text_document"
          - "--vocab-file=/data/roberta-large-mnli-vocab.json"
          - "--merge-file=/data/roberta-large-mnli-merges.txt"
          - "--data-impl=mmap"
          - "--split=949,50,1"
          - "--distributed-backend=nccl"
          - "--lr=1.5e-4"
          - "--lr-decay-style=cosine"
          - "--min-lr=1.0e-5"
          - "--weight-decay=1e-2"
          - "--clip-grad=1.0"
          - "--warmup=0.01"
          - "--checkpoint-activations"
          - "--log-interval=1"
          - "--save-interval=500"
          - "--eval-interval=100"
          - "--eval-iters=10"
          - "--fp16"
          - "--deepspeed"
          - "--deepspeed_config=/workspace/external/deepspeed/DeepSpeedExamples/Megatron-LM-v1.1.5-3D_parallelism/examples/ds_config.json"
          - "--zero-stage=0"
          - "--zero-reduce-bucket-size=50000000"
          - "--zero-allgather-bucket-size=5000000000"
        resources:
          limits:
            nvidia.com/gpu: 1
        volumeMounts:
          - mountPath: /data
            name: data
            subPath: data
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: efs-a-claim

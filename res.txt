ARGS localhost encoder 1 /home/gaoziyuan/project/bamboo/project_pactum/external/deepspeed/DeepSpeedExamples/pipeline_parallelism/transformer
RUNNING CMD export PROJECT_PACTUM_LOGGING_WARNING='etcd.client,etcd.lock,torch.distributed.distributed_c10d' 	export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python 	export LOGLEVEL=INFO 	&& 	export PYTHONPATH=/home/gaoziyuan/project/bamboo/project-pactum:${PYTHONPATH} 	&& 	python -m project_pactum.run 	--rdzv_backend=etcd-v2 	--rdzv_endpoint=localhost:2379 	--rdzv_id=encoder 	--nnodes=1:64 	--nproc_per_node=1 	--project-pactum 	--max-pipe-parallel-size=24 	--default-num-stages=1 	/home/gaoziyuan/project/bamboo/project_pactum/external/deepspeed/DeepSpeedExamples/pipeline_parallelism/transformer.py 	--backend=nccl 	--redundancy_level=1 	 	--deepspeed 	--deepspeed_config /home/gaoziyuan/project/bamboo/project_pactum/external/deepspeed/DeepSpeedExamples/pipeline_parallelism/transformer.json
[1;36m[0.002 p69799/t140608374449088 INFO project_pactum.run.api][m [36margs: Namespace(default_num_stages=1, log_dir=None, master_addr='127.0.0.1', master_port=29500, max_pipe_parallel_size=24, max_restarts=0, module=False, monitor_interval=5, nnodes='1:64', no_python=False, node_rank=0, nproc_per_node='1', project_pactum=True, rdzv_backend='etcd-v2', rdzv_conf='', rdzv_endpoint='localhost:2379', rdzv_id='encoder', redirects='0', role='default', run_path=False, standalone=False, start_method='spawn', tee='0', training_script='/home/gaoziyuan/project/bamboo/project_pactum/external/deepspeed/DeepSpeedExamples/pipeline_parallelism/transformer.py', training_script_args=['--backend=nccl', '--redundancy_level=1', '--deepspeed', '--deepspeed_config', '/home/gaoziyuan/project/bamboo/project_pactum/external/deepspeed/DeepSpeedExamples/pipeline_parallelism/transformer.json'], use_env=True)[m
[1;36m[0.038 p69799/t140608374449088 INFO root][m [36mUsing nproc_per_node=1.[m
[1;36m[0.038 p69799/t140608374449088 INFO project_pactum.run.api][m [36mStarting elastic_operator with launch configs:
  entrypoint             : /home/gaoziyuan/miniconda3/envs/Bamboo/bin/python
  min_nodes              : 1
  max_nodes              : 64
  nproc_per_node         : 1
  run_id                 : encoder
  rdzv_backend           : etcd-v2
  rdzv_endpoint          : localhost:2379
  rdzv_configs           : {'last_call_timeout': 5, 'timeout': 900}
  max_restarts           : 0
  monitor_interval       : 5
  log_dir                : None
  metrics_cfg            : {}
  max_pipe_parallel_size : 24
  default_pipeline_size  : 1
[m
[1;33m[0.038 p69799/t140608374449088 WARNING project_pactum.etcd][m [33mStart create_rdzv_handler[m
WARNING 2024-03-05 19:34:18,543 Etcd machines: ['http://localhost:2379', 'http://localhost:4001']
[1;33m[0.045 p69799/t140608374449088 WARNING project_pactum.etcd][m [33mEnd create_rdzv_handler[m
[1;36m[0.046 p69799/t140608374449088 INFO project_pactum.agent.api][m [36mlog directory set to: /tmp/torchelastic_m9uz9h0c/encoder_371tlxp9[m
[1;36m[0.052 p69799/t140608374449088 INFO project_pactum.agent.api][m [36m[default] starting workers for entrypoint: python[m
[1;36m[0.057 p69799/t140608374449088 INFO torch.distributed.elastic.agent.server.api][m [36m[default] Rendezvous'ing worker group[m
WARNING 2024-03-05 19:34:18,565 Attempting to join next rendezvous
[1;33m[0.067 p69799/t140608374449088 WARNING project_pactum.etcd][m [33m/torchelastic/p2p/run_encoder/rdzv/active_version[m
WARNING 2024-03-05 19:34:18,773 New rendezvous state created: {'status': 'joinable', 'version': '1', 'participants': []}
WARNING 2024-03-05 19:34:18,873 Joined rendezvous version 1 as rank 0. Full state: {'status': 'joinable', 'version': '1', 'participants': [0]}
WARNING 2024-03-05 19:34:18,879 Rank 0 is responsible for join last call.
WARNING 2024-03-05 19:34:24,120 Rank 0 finished join last call.
WARNING 2024-03-05 19:34:24,126 Waiting for remaining peers.
WARNING 2024-03-05 19:34:24,169 All peers arrived. Confirming membership.
[1;33m[5.988 p69799/t140608374449088 WARNING project_pactum.etcd][m [33mnum_active_nodes: 1[m
[1;33m[5.994 p69799/t140608374449088 WARNING project_pactum.etcd][m [33mnum_participants: 1[m
WARNING 2024-03-05 19:34:24,665 Waiting for confirmations from all peers.
WARNING 2024-03-05 19:34:24,719 Rendezvous version 1 is complete. Final state: {'status': 'final', 'version': '1', 'participants': [0], 'keep_alives': ['/torchelastic/p2p/run_encoder/rdzv/v_1/rank_0'], 'num_workers_waiting': 0, 'previous_version': '-1', 'num_pipelines': '1', 'num_stages': '1'}
WARNING 2024-03-05 19:34:24,877 Creating EtcdStore as the c10d::Store implementation
[1;36m[6.833 p69799/t140608374449088 INFO project_pactum.agent.api][m [36m[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=zkyd
  master_port=58677
  group_rank=0
  group_world_size=1
  num_pipelines=1
  num_stages=1
  global_decision=[GlobalInfo(rank=0, previous_coordinates=[], active_coordinates=[[0, 0]])]
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]
[m
[1;36m[6.839 p69799/t140608374449088 INFO torch.distributed.elastic.agent.server.api][m [36m[default] Starting worker group[m
[1;36m[6.968 p69799/t140608374449088 INFO torch.distributed.elastic.multiprocessing][m [36mSetting worker0 reply file to: /tmp/torchelastic_m9uz9h0c/encoder_371tlxp9/attempt_0/0/error.json[m
[1;33m[0.446 p69957/t139774945141696 WARNING project_pactum.etcd][m [33mStart create_rdzv_handler[m
WARNING 2024-03-05 19:34:27,332 Etcd machines: ['http://localhost:2379', 'http://localhost:4001']
[1;33m[0.463 p69957/t139774945141696 WARNING project_pactum.etcd][m [33mEnd create_rdzv_handler[m
WARNING 2024-03-05 19:34:27,344 Creating EtcdStore as the c10d::Store implementation
[2024-03-05 19:34:27,345] [INFO] [distributed.py:52:init_distributed] Initializing torch distributed with backend: nccl
STARTING WITH RANK = 0 and world size = 1 and init_method = None
[1;35m[0.516 p69957/t139774945141696 DEBUG deepspeed.utils.distributed][m [35mâ˜…â˜†â˜…â˜†â˜…â˜†â˜…â˜†â˜…â˜†â˜… FINISHED DIST INITIALIZATION â˜…â˜†â˜…â˜†â˜…â˜†â˜…â˜†â˜…â˜†â˜…[m
SEED_LAYERS=False BASE_SEED=1234 SEED_FN=None
[2024-03-05 19:34:27,564] [INFO] [module.py:581:_partition_layers] Partitioning pipeline stages with method uniform
parts=[0, 10]
stage=0 layers=10
     0: EncoderLayer
     1: EncoderLayer
     2: EncoderLayer
     3: EncoderLayer
     4: EncoderLayer
     5: EncoderLayer
     6: EncoderLayer
     7: EncoderLayer
     8: LayerNorm
     9: <lambda>
  loss: MSELoss
[2024-03-05 19:34:44,089] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed info: version=0.5.2+0803f89, git-hash=0803f89, git-branch=main
[1;33m[17.210 p69957/t139774945141696 WARNING project_pactum.etcd][m [33mStart create_rdzv_handler[m
WARNING 2024-03-05 19:34:44,094 Etcd machines: ['http://localhost:2379', 'http://localhost:4001']
[1;33m[17.221 p69957/t139774945141696 WARNING project_pactum.etcd][m [33mEnd create_rdzv_handler[m
[2024-03-05 19:34:44,101] [INFO] [engine.py:175:__init__] Started rendezvous handler
WARNING 2024-03-05 19:34:44,102 Creating EtcdStore as the c10d::Store implementation
[2024-03-05 19:34:44,219] [INFO] [engine.py:242:__init__] DeepSpeed Flops Profiler Enabled: False
Using /home/gaoziyuan/.cache/torch_extensions/py37_cu117 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/gaoziyuan/.cache/torch_extensions/py37_cu117/fused_adam/build.ninja...
Building extension module fused_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module fused_adam...
Time to load fused_adam op: 0.32738542556762695 seconds
[2024-03-05 19:34:45,061] [INFO] [engine.py:930:_configure_optimizer] Using DeepSpeed Optimizer param name adam as basic optimizer
[2024-03-05 19:34:45,067] [INFO] [engine.py:937:_configure_optimizer] DeepSpeed Basic Optimizer = FusedAdam
[2024-03-05 19:34:45,068] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed Final Optimizer = adam
[2024-03-05 19:34:45,068] [INFO] [engine.py:665:_configure_lr_scheduler] DeepSpeed using client LR scheduler
[2024-03-05 19:34:45,068] [INFO] [logging.py:68:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2024-03-05 19:34:45,068] [INFO] [config.py:940:print] DeepSpeedEngine configuration:
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   allreduce_always_fp32 ........ False
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   amp_enabled .................. False
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   amp_params ................... False
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   checkpoint_tag_validation_enabled  True
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   checkpoint_tag_validation_fail  False
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   curriculum_enabled ........... False
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   curriculum_params ............ False
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   dataloader_drop_last ......... False
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   disable_allgather ............ False
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   dump_state ................... False
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   dynamic_loss_scale_args ...... None
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   eigenvalue_enabled ........... False
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-05 19:34:45,069] [INFO] [config.py:944:print]   eigenvalue_layer_num ......... 0
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   eigenvalue_max_iter .......... 100
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   eigenvalue_stability ......... 1e-06
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   eigenvalue_tol ............... 0.01
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   eigenvalue_verbose ........... False
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   elasticity_enabled ........... False
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   fp16_enabled ................. False
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   fp16_master_weights_and_gradients  False
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   fp16_mixed_quantize .......... False
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   global_rank .................. 0
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   gradient_accumulation_steps .. 4
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   gradient_clipping ............ 0.0
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   gradient_predivide_factor .... 1.0
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   initial_dynamic_scale ........ 4294967296
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   loss_scale ................... 0
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   memory_breakdown ............. False
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   optimizer_legacy_fusion ...... False
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   optimizer_name ............... adam
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   optimizer_params ............. {'lr': 0.001, 'betas': [0.9, 0.999], 'eps': 1e-08}
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   pld_enabled .................. False
[2024-03-05 19:34:45,070] [INFO] [config.py:944:print]   pld_params ................... False
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   prescale_gradients ........... False
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   quantize_change_rate ......... 0.001
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   quantize_groups .............. 1
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   quantize_offset .............. 1000
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   quantize_period .............. 1000
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   quantize_rounding ............ 0
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   quantize_start_bits .......... 16
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   quantize_target_bits ......... 8
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   quantize_training_enabled .... False
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   quantize_type ................ 0
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   quantize_verbose ............. False
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   scheduler_name ............... None
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   scheduler_params ............. None
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   sparse_attention ............. None
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   sparse_gradients_enabled ..... False
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   steps_per_print .............. 1
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   tensorboard_enabled .......... False
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   tensorboard_job_name ......... DeepSpeedJobName
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   tensorboard_output_path ...... 
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   train_batch_size ............. 32
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   train_micro_batch_size_per_gpu  8
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   use_quantizer_kernel ......... False
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   wall_clock_breakdown ......... False
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   world_size ................... 1
[2024-03-05 19:34:45,071] [INFO] [config.py:944:print]   zero_allow_untested_optimizer  False
[2024-03-05 19:34:45,072] [INFO] [config.py:944:print]   zero_config .................. {
    "stage": 0, 
    "contiguous_gradients": true, 
    "reduce_scatter": true, 
    "reduce_bucket_size": 5.000000e+08, 
    "allgather_partitions": true, 
    "allgather_bucket_size": 5.000000e+08, 
    "overlap_comm": false, 
    "load_from_fp32_weights": true, 
    "elastic_checkpoint": true, 
    "offload_param": null, 
    "offload_optimizer": null, 
    "sub_group_size": 1.000000e+09, 
    "prefetch_bucket_size": 5.000000e+07, 
    "param_persistence_threshold": 1.000000e+05, 
    "max_live_parameters": 1.000000e+09, 
    "max_reuse_distance": 1.000000e+09, 
    "gather_fp16_weights_on_model_save": false, 
    "ignore_unused_parameters": true, 
    "round_robin_gradients": false, 
    "legacy_stage1": false
}
[2024-03-05 19:34:45,072] [INFO] [config.py:944:print]   zero_enabled ................. False
[2024-03-05 19:34:45,072] [INFO] [config.py:944:print]   zero_optimization_stage ...... 0
[2024-03-05 19:34:45,072] [INFO] [config.py:951:print]   json = {
    "train_batch_size": 32, 
    "train_micro_batch_size_per_gpu": 8, 
    "optimizer": {
        "type": "Adam", 
        "params": {
            "lr": 0.001, 
            "betas": [0.9, 0.999], 
            "eps": 1e-08
        }
    }, 
    "steps_per_print": 1, 
    "wall_clock_breakdown": false
}
Using /home/gaoziyuan/.cache/torch_extensions/py37_cu117 as PyTorch extensions root...
Emitting ninja build file /home/gaoziyuan/.cache/torch_extensions/py37_cu117/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.3232753276824951 seconds
[2024-03-05 19:34:45,396] [INFO] [engine.py:133:__init__] CONFIG: micro_batches=4 micro_batch_size=8
[ 00|00 ] STARTING BATCH 0 with coordinates [[0, 0]]
[DEBUG Pipeline] Instructions in step 0: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=0),ForwardPass(buffer_id=0, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=0)
cmd: ForwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 1: BackwardPass(buffer_id=0, stage_id=0)


cmd: BackwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 2: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=1),ForwardPass(buffer_id=1, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=1)
cmd: ForwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 3: BackwardPass(buffer_id=1, stage_id=0)


cmd: BackwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 4: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=2),ForwardPass(buffer_id=2, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=2)
cmd: ForwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 5: BackwardPass(buffer_id=2, stage_id=0)


cmd: BackwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 6: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=3),ForwardPass(buffer_id=3, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=3)
cmd: ForwardPass(buffer_id=3, stage_id=0)
[DEBUG Pipeline] Instructions in step 7: BackwardPass(buffer_id=3, stage_id=0),ReduceGrads(stage_id=0),OptimizerStep()


cmd: BackwardPass(buffer_id=3, stage_id=0)
cmd: ReduceGrads(stage_id=0)
cmd: OptimizerStep()
[DEBUG Pipeline] Finish one iteration
[2024-03-05 19:34:46,768] [INFO] [engine.py:1422:train_batch] steps: 1 loss: 1.0159 iter time (s): 1.113 samples/sec: 28.761
[ 00|01 ] FINISHING BATCH 1 at 2024-03-05 19:34:46 took 1.121612787246704 s
[ 00|01 ] STARTING BATCH 1 with coordinates [[0, 0]]
[DEBUG Pipeline] Instructions in step 0: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=0),ForwardPass(buffer_id=0, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=0)
cmd: ForwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 1: BackwardPass(buffer_id=0, stage_id=0)


cmd: BackwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 2: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=1),ForwardPass(buffer_id=1, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=1)
cmd: ForwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 3: BackwardPass(buffer_id=1, stage_id=0)


cmd: BackwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 4: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=2),ForwardPass(buffer_id=2, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=2)
cmd: ForwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 5: BackwardPass(buffer_id=2, stage_id=0)


cmd: BackwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 6: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=3),ForwardPass(buffer_id=3, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=3)
cmd: ForwardPass(buffer_id=3, stage_id=0)
[DEBUG Pipeline] Instructions in step 7: BackwardPass(buffer_id=3, stage_id=0),ReduceGrads(stage_id=0),OptimizerStep()


cmd: BackwardPass(buffer_id=3, stage_id=0)
cmd: ReduceGrads(stage_id=0)
cmd: OptimizerStep()
[DEBUG Pipeline] Finish one iteration
[2024-03-05 19:34:47,640] [INFO] [engine.py:1422:train_batch] steps: 2 loss: 2.3227 iter time (s): 0.858 samples/sec: 37.299
[ 00|02 ] FINISHING BATCH 2 at 2024-03-05 19:34:47 took 0.8685417175292969 s
[ 00|02 ] STARTING BATCH 2 with coordinates [[0, 0]]
[DEBUG Pipeline] Instructions in step 0: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=0),ForwardPass(buffer_id=0, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=0)
cmd: ForwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 1: BackwardPass(buffer_id=0, stage_id=0)


cmd: BackwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 2: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=1),ForwardPass(buffer_id=1, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=1)
cmd: ForwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 3: BackwardPass(buffer_id=1, stage_id=0)


cmd: BackwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 4: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=2),ForwardPass(buffer_id=2, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=2)
cmd: ForwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 5: BackwardPass(buffer_id=2, stage_id=0)


cmd: BackwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 6: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=3),ForwardPass(buffer_id=3, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=3)
cmd: ForwardPass(buffer_id=3, stage_id=0)
[DEBUG Pipeline] Instructions in step 7: BackwardPass(buffer_id=3, stage_id=0),ReduceGrads(stage_id=0),OptimizerStep()


cmd: BackwardPass(buffer_id=3, stage_id=0)
cmd: ReduceGrads(stage_id=0)
cmd: OptimizerStep()
[DEBUG Pipeline] Finish one iteration
[2024-03-05 19:34:48,511] [INFO] [engine.py:1422:train_batch] steps: 3 loss: 1.3512 iter time (s): 0.852 samples/sec: 37.568
[ 00|03 ] FINISHING BATCH 3 at 2024-03-05 19:34:48 took 0.8650901317596436 s
[ 00|03 ] STARTING BATCH 3 with coordinates [[0, 0]]
[DEBUG Pipeline] Instructions in step 0: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=0),ForwardPass(buffer_id=0, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=0)
cmd: ForwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 1: BackwardPass(buffer_id=0, stage_id=0)


cmd: BackwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 2: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=1),ForwardPass(buffer_id=1, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=1)
cmd: ForwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 3: BackwardPass(buffer_id=1, stage_id=0)


cmd: BackwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 4: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=2),ForwardPass(buffer_id=2, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=2)
cmd: ForwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 5: BackwardPass(buffer_id=2, stage_id=0)


cmd: BackwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 6: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=3),ForwardPass(buffer_id=3, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=3)
cmd: ForwardPass(buffer_id=3, stage_id=0)
[DEBUG Pipeline] Instructions in step 7: BackwardPass(buffer_id=3, stage_id=0),ReduceGrads(stage_id=0),OptimizerStep()


cmd: BackwardPass(buffer_id=3, stage_id=0)
cmd: ReduceGrads(stage_id=0)
cmd: OptimizerStep()
[DEBUG Pipeline] Finish one iteration
[2024-03-05 19:34:49,387] [INFO] [engine.py:1422:train_batch] steps: 4 loss: 1.2125 iter time (s): 0.861 samples/sec: 37.171
[ 00|04 ] FINISHING BATCH 4 at 2024-03-05 19:34:49 took 0.8712117671966553 s
[ 00|04 ] STARTING BATCH 4 with coordinates [[0, 0]]
[DEBUG Pipeline] Instructions in step 0: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=0),ForwardPass(buffer_id=0, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=0)
cmd: ForwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 1: BackwardPass(buffer_id=0, stage_id=0)


cmd: BackwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 2: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=1),ForwardPass(buffer_id=1, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=1)
cmd: ForwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 3: BackwardPass(buffer_id=1, stage_id=0)


cmd: BackwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 4: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=2),ForwardPass(buffer_id=2, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=2)
cmd: ForwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 5: BackwardPass(buffer_id=2, stage_id=0)


cmd: BackwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 6: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=3),ForwardPass(buffer_id=3, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=3)
cmd: ForwardPass(buffer_id=3, stage_id=0)
[DEBUG Pipeline] Instructions in step 7: BackwardPass(buffer_id=3, stage_id=0),ReduceGrads(stage_id=0),OptimizerStep()


cmd: BackwardPass(buffer_id=3, stage_id=0)
cmd: ReduceGrads(stage_id=0)
cmd: OptimizerStep()
[DEBUG Pipeline] Finish one iteration
[2024-03-05 19:34:50,270] [INFO] [engine.py:1422:train_batch] steps: 5 loss: 1.0803 iter time (s): 0.864 samples/sec: 37.030
[ 00|05 ] FINISHING BATCH 5 at 2024-03-05 19:34:50 took 0.8790724277496338 s
[ 00|05 ] STARTING BATCH 5 with coordinates [[0, 0]]
[DEBUG Pipeline] Instructions in step 0: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=0),ForwardPass(buffer_id=0, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=0)
cmd: ForwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 1: BackwardPass(buffer_id=0, stage_id=0)


cmd: BackwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 2: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=1),ForwardPass(buffer_id=1, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=1)
cmd: ForwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 3: BackwardPass(buffer_id=1, stage_id=0)


cmd: BackwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 4: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=2),ForwardPass(buffer_id=2, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=2)
cmd: ForwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 5: BackwardPass(buffer_id=2, stage_id=0)


cmd: BackwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 6: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=3),ForwardPass(buffer_id=3, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=3)
cmd: ForwardPass(buffer_id=3, stage_id=0)
[DEBUG Pipeline] Instructions in step 7: BackwardPass(buffer_id=3, stage_id=0),ReduceGrads(stage_id=0),OptimizerStep()


cmd: BackwardPass(buffer_id=3, stage_id=0)
cmd: ReduceGrads(stage_id=0)
cmd: OptimizerStep()
[DEBUG Pipeline] Finish one iteration
[2024-03-05 19:34:51,145] [INFO] [engine.py:1422:train_batch] steps: 6 loss: 1.1088 iter time (s): 0.859 samples/sec: 37.260
[ 00|06 ] FINISHING BATCH 6 at 2024-03-05 19:34:51 took 0.8690078258514404 s
[ 00|06 ] STARTING BATCH 6 with coordinates [[0, 0]]
[DEBUG Pipeline] Instructions in step 0: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=0),ForwardPass(buffer_id=0, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=0)
cmd: ForwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 1: BackwardPass(buffer_id=0, stage_id=0)


cmd: BackwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 2: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=1),ForwardPass(buffer_id=1, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=1)
cmd: ForwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 3: BackwardPass(buffer_id=1, stage_id=0)


cmd: BackwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 4: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=2),ForwardPass(buffer_id=2, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=2)
cmd: ForwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 5: BackwardPass(buffer_id=2, stage_id=0)


cmd: BackwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 6: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=3),ForwardPass(buffer_id=3, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=3)
cmd: ForwardPass(buffer_id=3, stage_id=0)
[DEBUG Pipeline] Instructions in step 7: BackwardPass(buffer_id=3, stage_id=0),ReduceGrads(stage_id=0),OptimizerStep()


cmd: BackwardPass(buffer_id=3, stage_id=0)
cmd: ReduceGrads(stage_id=0)
cmd: OptimizerStep()
[DEBUG Pipeline] Finish one iteration
[2024-03-05 19:34:52,019] [INFO] [engine.py:1422:train_batch] steps: 7 loss: 1.0154 iter time (s): 0.853 samples/sec: 37.503
[ 00|07 ] FINISHING BATCH 7 at 2024-03-05 19:34:52 took 0.8680334091186523 s
[ 00|07 ] STARTING BATCH 7 with coordinates [[0, 0]]
[DEBUG Pipeline] Instructions in step 0: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=0),ForwardPass(buffer_id=0, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=0)
cmd: ForwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 1: BackwardPass(buffer_id=0, stage_id=0)


cmd: BackwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 2: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=1),ForwardPass(buffer_id=1, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=1)
cmd: ForwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 3: BackwardPass(buffer_id=1, stage_id=0)


cmd: BackwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 4: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=2),ForwardPass(buffer_id=2, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=2)
cmd: ForwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 5: BackwardPass(buffer_id=2, stage_id=0)


cmd: BackwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 6: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=3),ForwardPass(buffer_id=3, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=3)
cmd: ForwardPass(buffer_id=3, stage_id=0)
[DEBUG Pipeline] Instructions in step 7: BackwardPass(buffer_id=3, stage_id=0),ReduceGrads(stage_id=0),OptimizerStep()


cmd: BackwardPass(buffer_id=3, stage_id=0)
cmd: ReduceGrads(stage_id=0)
cmd: OptimizerStep()
[DEBUG Pipeline] Finish one iteration
[2024-03-05 19:34:52,898] [INFO] [engine.py:1422:train_batch] steps: 8 loss: 1.0929 iter time (s): 0.858 samples/sec: 37.311
[ 00|08 ] FINISHING BATCH 8 at 2024-03-05 19:34:52 took 0.8731353282928467 s
[ 00|08 ] STARTING BATCH 8 with coordinates [[0, 0]]
[DEBUG Pipeline] Instructions in step 0: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=0),ForwardPass(buffer_id=0, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=0)
cmd: ForwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 1: BackwardPass(buffer_id=0, stage_id=0)


cmd: BackwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 2: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=1),ForwardPass(buffer_id=1, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=1)
cmd: ForwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 3: BackwardPass(buffer_id=1, stage_id=0)


cmd: BackwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 4: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=2),ForwardPass(buffer_id=2, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=2)
cmd: ForwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 5: BackwardPass(buffer_id=2, stage_id=0)


cmd: BackwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 6: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=3),ForwardPass(buffer_id=3, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=3)
cmd: ForwardPass(buffer_id=3, stage_id=0)
[DEBUG Pipeline] Instructions in step 7: BackwardPass(buffer_id=3, stage_id=0),ReduceGrads(stage_id=0),OptimizerStep()


cmd: BackwardPass(buffer_id=3, stage_id=0)
cmd: ReduceGrads(stage_id=0)
cmd: OptimizerStep()
[DEBUG Pipeline] Finish one iteration
[2024-03-05 19:34:53,766] [INFO] [engine.py:1422:train_batch] steps: 9 loss: 1.0621 iter time (s): 0.849 samples/sec: 37.705
[ 00|09 ] FINISHING BATCH 9 at 2024-03-05 19:34:53 took 0.8618900775909424 s
[ 00|09 ] STARTING BATCH 9 with coordinates [[0, 0]]
[DEBUG Pipeline] Instructions in step 0: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=0),ForwardPass(buffer_id=0, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=0)
cmd: ForwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 1: BackwardPass(buffer_id=0, stage_id=0)


cmd: BackwardPass(buffer_id=0, stage_id=0)
[DEBUG Pipeline] Instructions in step 2: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=1),ForwardPass(buffer_id=1, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=1)
cmd: ForwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 3: BackwardPass(buffer_id=1, stage_id=0)


cmd: BackwardPass(buffer_id=1, stage_id=0)
[DEBUG Pipeline] Instructions in step 4: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=2),ForwardPass(buffer_id=2, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=2)
cmd: ForwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 5: BackwardPass(buffer_id=2, stage_id=0)


cmd: BackwardPass(buffer_id=2, stage_id=0)
[DEBUG Pipeline] Instructions in step 6: RecvActivation(buffer_id=-1, stage_id=0),LoadMicroBatch(buffer_id=3),ForwardPass(buffer_id=3, stage_id=0)


cmd: RecvActivation(buffer_id=-1, stage_id=0)
cmd: LoadMicroBatch(buffer_id=3)
cmd: ForwardPass(buffer_id=3, stage_id=0)
[DEBUG Pipeline] Instructions in step 7: BackwardPass(buffer_id=3, stage_id=0),ReduceGrads(stage_id=0),OptimizerStep()


cmd: BackwardPass(buffer_id=3, stage_id=0)
cmd: ReduceGrads(stage_id=0)
cmd: OptimizerStep()
[DEBUG Pipeline] Finish one iteration
[2024-03-05 19:34:54,644] [INFO] [engine.py:1422:train_batch] steps: 10 loss: 1.0171 iter time (s): 0.861 samples/sec: 37.178
[ 00|10 ] FINISHING BATCH 10 at 2024-03-05 19:34:54 took 0.8728649616241455 s
Finish Successfully
[1;36m[37.092 p69799/t140608374449088 INFO project_pactum.agent.api][m [36m[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.[m
[1;36m[37.098 p69799/t140608374449088 INFO torch.distributed.elastic.agent.server.api][m [36mLocal worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish[m
[1;36m[37.212 p69799/t140608374449088 INFO torch.distributed.elastic.agent.server.api][m [36mDone waiting for other agents. Elapsed: 0.1082460880279541 seconds[m
